---
title: 如何使用语音服务创建声学模型 - Microsoft 认知服务 | Microsoft Docs
description: 了解如何使用 Microsoft 认知服务中的语音服务创建声学模型。
services: cognitive-services
author: PanosPeriorellis
manager: onano
ms.service: cognitive-services
ms.component: speech-service
ms.topic: tutorial
ms.date: 06/25/2018
ms.author: panosper
ms.openlocfilehash: 32dc9015f5e1a58d02571eb84e6ceeb0e9e8582d
ms.sourcegitcommit: 0b05bdeb22a06c91823bd1933ac65b2e0c2d6553
ms.translationtype: HT
ms.contentlocale: zh-CN
ms.lasthandoff: 07/17/2018
ms.locfileid: "39069033"
---
# <a name="tutorial-create-a-custom-acoustic-model"></a>教程：创建自定义声学模型

如果应用程序设计用于特定的环境（例如汽车）、特定的录制设备或条件，或特定的用户群，则创建自定义声学模型会很有帮助。 示例包括带有口音的讲话、特定的背景噪音，或使用特定的麦克风录制音频。

本页面介绍以下操作：
> [!div class="checklist"]
> * 准备数据
> * 导入声学数据集
> * 创建自定义声学模型

如果没有认知服务帐户，请在开始之前创建一个[免费帐户](https://azure.microsoft.com/try/cognitive-services)。

## <a name="prerequisites"></a>先决条件

打开[认知服务订阅](https://customspeech.ai/Subscriptions)页，确保认知服务帐户已连接到某个订阅。

可以单击“连接现有的订阅”按钮，连接到在 Azure 门户中创建的语音服务订阅。

有关在 Azure 门户中创建语音服务订阅的信息，请参阅[入门](get-started.md)页。

## <a name="prepare-the-data"></a>准备数据

若要自定义特定域的声学模型，需要一系列语音数据。 这些数据可以是几条陈述，也可以是几百个小时的讲话。 此数据集合包括一组语音数据音频文件，以及每个音频文件的听录文本文件。 音频数据应该代表要在其中使用识别器的场景。

例如：

*   若要更好地识别嘈杂工厂环境中的语音，音频文件应包括嘈杂工厂中的讲话人。
*   如果想要优化单个讲话人的性能（例如，罗斯福总统的所有炉边谈话），可以听录他的所有言语，然后，音频文件应该只会包括该讲话人的多个示例。

用于自定义声学模型的声学数据集由两个部分组成：(1) 一组包含语音数据的音频文件；(2) 一个包含所有音频文件听录内容的文件。

### <a name="audio-data-recommendations"></a>音频数据建议

*   应该以 WAV (RIFF) 音频格式存储数据集中的所有音频文件。
*   音频的采样率必须是 8 kHz 或 16 kHz，样本值应存储为未压缩的 PCM 16 位带符号整数（短型）。
*   支持仅单声道（单音）音频文件。
*   音频文件的长度必须为 100 毫秒到 1 分钟。 每个音频文件的开头和末尾最好是至少有 100 毫秒的寂静区（往往是 500 毫秒到 1 秒）。
*   如果数据中包含背景噪音，则我们建议在数据中讲话内容的前面和/或后面另外包含一些具有更长寂静区的示例（例如，几秒钟的寂静区）。
*   每个音频文件应包含一条陈述（例如，一条听写句子）、一个查询，或者对话系统的一个轮次。
*   数据集中的每个音频文件应有唯一的文件名和扩展名“wav”。
*   音频文件集应放置到不带子目录的单个文件夹中，整个音频文件集应打包为单个 ZIP 文件存档。

> [!NOTE]
> 通过 Web 门户导入的数据目前限制为 2 GB，因此，这是声学数据集的最大大小。 这相当于以 16 kHz 频率录制了 17 个小时的音频，或者以 8 kHz 的频率录制了 34 个小时的音频。 下表汇总了音频数据的主要要求。
>

| 属性 | 值 |
|---------- |----------|
| 文件格式 | RIFF (WAV) |
| 采样率 | 8000 Hz 或 16,000 Hz |
| 声道 | 1（单音） |
| 样本格式 | PCM，16 位整数 |
| 文件持续时间 | 0.1 秒 < 持续时间 < 60 秒 |
| 无声凸环 | > 0.1 秒 |
| 存档格式 | Zip |
| 最大存档大小 | 2 GB |

## <a name="language-support"></a>语言支持

自定义“语音转文本”语言模型支持以下语言。

单击“受支持语言”的完整列表[](supported-languages.md)

### <a name="transcriptions-for-the-audio-dataset"></a>音频数据集的听录

应在单个纯文本文件中包含所有 WAV 文件的听录。 听录文件的每一行应包含一个音频文件的名称，后接相应的听录。 文件名和听录应以制表符 (\t) 分隔。

  例如：
```
  speech01.wav  speech recognition is awesome
  speech02.wav  the quick brown fox jumped all over the place
  speech03.wav  the lazy dog was not amused
```
> [!NOTE]
> 听录应编码为 UTF-8 Bom

听录内容应经过文本规范化，以便可由系统处理。 但是，用户在将数据上传到自定义语音服务之前，必须完成一些重要的规范化操作。 在准备听录内容时，请参阅相应语言的[听录准则](prepare-transcription.md)部分。

使用[语音服务门户](https://customspeech.ai)完成以下步骤。

## <a name="import-the-acoustic-data-set"></a>导入声学数据集

准备好音频文件和听录内容后，可将其导入服务 Web 门户。

为此，请先确保已登录到[语音服务门户](https://customspeech.ai)。 然后单击顶部功能区的“自定义语音”下拉菜单，选择“适应数据”。 如果这是第一次将数据上传到自定义语音服务，则会看到名为“数据集”的空表。 

单击“声学数据集”行中的“导入”按钮，此时站点会显示一个用于上传新数据集的页面。

![尝试](media/stt/speech-acoustic-datasets-import.png)

在相应的文本框中输入_名称_和_说明_。 友好的说明有助于跟踪上传的各种数据集。 接下来，单击“听录文件”和“WAV 文件”旁边的“选择文件”，并分别选择纯文本格式的听录文件，以及 zip 存档格式的 WAV 文件。 准备工作完成后，单击“导入”上传数据。 随后将会上传数据。 上传大型数据集可能需要花费几分钟时间。

上传完成后，会返回到“声学数据集”表，并会看到一个对应于声学数据集的条目。 请注意，为该条目分配了一个唯一 ID (GUID)。 此数据还会有一个反映其当前状态的状态。 如果正在排队等待处理，则其状态为“未启动”；如果正在进行验证，则其状态为“正在运行”；如果数据已做好使用准备，则其状态为“完成”。

数据验证包括针对音频文件执行一系列检查以验证文件格式、长度和采样率，并针对听录文件执行一系列检查以验证文件格式和执行一些文本规范化操作。

当状态为“成功”时，可以单击“详细信息”查看声学数据验证报告。 此时会显示通过验证和未通过验证的陈述的数目，以及未通过验证的陈述的详细信息。 在以下示例中，有两个 WAV 文件由于音频格式不正确而未通过验证（在此数据集中，一个文件的采样率不正确，另一个文件的文件格式不正确）。

![尝试](media/stt/speech-acoustic-datasets-report.png)

在某个时候，如果你要更改数据集的名称或说明，可以单击“编辑”链接并更改这些条目。 无法修改音频文件或听录。

## <a name="create-a-custom-acoustic-model"></a>创建自定义声学模型

当声学数据集的状态为“完成”后，可以使用它来创建自定义声学模型。 为此，请单击“自定义语音”下拉菜单中的“声学模型”。 此时会显示一个名为“你的模型”的表，其中列出了所有自定义声学模型。 首次使用时，此表为空。 当前区域设置显示在表标题中。 目前，只能为“美国英语”创建声学模型。

若要创建新模型，请单击表标题下的“新建”。 像前面一样，输入名称和说明以帮助识别此模型。 例如，可以使用“说明”字段来记录创建模型时使用了哪个起始模型和声学数据集。 接下来，在下拉菜单中选择一个“基本声学模型”。 基本模型是用作自定义操作的起点的模型。 有两个基本声学模型可供选择。 “Microsoft 搜索和听写 AM”适用于在应用程序中发出的语音，例如命令、搜索查询或听写。 “Microsoft 对话模型”适用于识别以对话形式说出的语音。 此类语音通常是面对另一个人在呼叫中心或会议中发出。 “对话”模型中部分结果的延迟高于“搜索”和“听写”模型中的延迟。

> [!NOTE]
> 我们即将推出新的“通用”模型，旨在解决所有方案的要求。 到时，上述模型仍可公开使用。

接下来，使用下拉菜单选择要用于执行自定义的声学数据。

![尝试](media/stt/speech-acoustic-models-create2.png)

处理完成后，可根据需要选择对新模型执行准确度测试。 这会使用自定义的声学模型针对指定的声学数据集运行语音到文本的评估，并报告结果。 若要执行此测试，请选中“准确度测试”复选框。 然后，从下拉菜单中选择一个语言模型。 如果尚未创建任何自定义语言模型，则下拉列表中只会显示基本语言模型。 参阅指南中基本语言模型的[说明](how-to-customize-language-model.md)，并选择最合适的模型。

最后，选择要用于评估自定义模型的声学数据集。 如果执行准确度测试，选择的声学数据必须不同于创建模型时所用的数据，这样才能获得真正有意义的模型性能。 基于训练数据测试准确度并不能评估修改后的模型在实际条件下的性能。 结果会过于乐观。 另请注意，准确度测试限制为 1000 条陈述。 如果要测试的声学数据集较大，则只会评估最前面的 1000 条陈述。

准备好开始运行自定义过程时，请按“创建”。

现在，声学模型表中会出现一个对应于此新模型的新条目。 过程的状态将反映在表中。 状态为“正在等待”、“正在处理”和“完成”。

![尝试](media/stt/speech-acoustic-models-creating.png)

## <a name="next-steps"></a>后续步骤

- [获取语音试用订阅](https://azure.microsoft.com/try/cognitive-services/)
- [如何在 C# 应用中识别语音](quickstart-csharp-dotnet-windows.md)
- [Git 示例数据](https://github.com/Microsoft/Cognitive-Custom-Speech-Service)
