---
title: 创建自定义语音语音服务
titleSuffix: Azure Cognitive Services
description: 如果已准备好上传数据，请切换到自定义语音门户。 创建或选择一个自定义语音项目。 项目必须共享正确的语言/区域设置和性别属性作为要用于语音训练的数据。
services: cognitive-services
author: erhopf
manager: nitinme
ms.service: cognitive-services
ms.subservice: speech-service
ms.topic: conceptual
ms.date: 11/04/2019
ms.author: erhopf
ms.openlocfilehash: bbe1d651a7d2d2cac1b1aa78b815b2797ad185c5
ms.sourcegitcommit: f52ce6052c795035763dbba6de0b50ec17d7cd1d
ms.translationtype: MT
ms.contentlocale: zh-CN
ms.lasthandoff: 01/24/2020
ms.locfileid: "76717327"
---
# <a name="create-a-custom-voice"></a>创建自定义语音

在[准备自定义语音数据](how-to-custom-voice-prepare-data.md)时，我们介绍了可用于训练自定义语音和不同格式要求的不同数据类型。 准备好数据后，可以开始将其上传到[自定义语音门户](https://aka.ms/custom-voice-portal)，或通过自定义语音训练 API。 本文介绍通过门户训练自定义语音的步骤。

> [!NOTE]
> 本页假设你已阅读[自定义语音入门](how-to-custom-voice.md)并[为自定义语音准备数据](how-to-custom-voice-prepare-data.md)，并已创建自定义语音项目。

检查自定义语音：语言所支持的语言[以进行自定义](language-support.md#customization)。

## <a name="upload-your-datasets"></a>데이터 세트 업로드

如果已准备好上传数据，请切换到[自定义语音门户](https://aka.ms/custom-voice-portal)。 创建或选择一个自定义语音项目。 项目必须共享正确的语言/区域设置和性别属性作为要用于语音训练的数据。 例如，如果您拥有的音频录音以英国强调，请选择 `en-GB`。

中转到 "**数据**" 选项卡，然后单击 "**上传数据**"。 在向导中，选择与准备就绪的正确数据类型。

你上载的每个数据集都必须满足你选择的数据类型的要求。 在上载数据之前，请务必正确设置数据的格式。 这可确保自定义语音服务将准确处理数据。 请参阅为[自定义语音准备数据](how-to-custom-voice-prepare-data.md)，并确保数据已本来格式。

> [!NOTE]
> 免费订阅（F0）用户可同时上传两个数据集。 标准订阅（S0）用户可以同时上传五个数据集。 업로드 개수가 초과되면 적어도 한 개의 데이터 세트에 대한 가져오기가 완료될 때까지 기다립니다. 그런 다음, 다시 시도하세요.

> [!NOTE]
> 每个订阅允许导入的数据集的最大数目为10个 .zip 文件（对于免费订阅（F0）用户）和500（对于标准订阅（S0）用户）。

命中 "上传" 按钮后，将自动验证数据集。 数据验证包括对音频文件的一系列检查，以验证其文件格式、大小和采样速率。 如果有错误，请修复错误，然后重新提交。 成功启动数据导入请求时，应会在数据表中看到对应于刚上传的数据集的条目。

다음 표에서는 가져온 데이터 세트에 대한 처리 상태를 보여 줍니다.

| 상태 | 의미 |
| ----- | ------- |
| 처리 중 | 数据集已接收并正在处理。 |
| 성공 | 您的数据集已经过验证，现可用于构建语音模型。 |
| 실패 | 数据集在处理过程中因多种原因而失败，例如，文件错误、数据问题或网络问题。 |

验证完成后，可以在**最谈话**列中查看每个数据集的匹配最谈话总数。 如果所选的数据类型需要长时间音频分段，此列只会根据您的脚本或通过语音脚本服务为您划分的最谈话反映。 可以进一步下载验证的数据集，以查看成功导入的最谈话的详细结果及其映射脚本。 提示：长时间音频分段可能需要超过一小时才能完成数据处理。

对于 en-us 和 zh-chs 数据集，可以进一步下载报表，查看每个录制的发音评分和噪音级别。 발음 점수의 범위는 0에서 100까지입니다. 일반적으로 70점 아래의 점수는 음성 오류 또는 스크립트 불일치를 나타냅니다. 악센트가 강하면 발음 점수를 떨어뜨리고 생성된 디지털 음성에 영향을 줄 수 있습니다.

SNR(신호 대 잡음 비율)이 더 높을 수록 오디오의 잡음이 더 낮은 것입니다. 일반적으로 전문 스튜디오에서 녹음하면 50 이상의 SNR에 도달할 수 있습니다. SNR이 20보다 낮은 오디오는 생성된 음성에서 잡음이 뚜렷하게 들릴 수 있습니다.

발음 점수가 낮거나 신호 대 잡음 비율이 떨어지는 모든 발화는 다시 녹음하는 것이 좋습니다. 다시 녹음할 수 없다면 해당 발화를 데이터 세트에서 제외할 수 있습니다.

## <a name="build-your-custom-voice-model"></a>构建自定义语音模型

验证数据集后，可以使用它来生成自定义语音模型。

1.  导航到**文本到语音 > 自定义语音 > 培训**。

2.  单击 "**训练模型**"。

3.  接下来，输入**名称**和**描述**以帮助您识别此模型。

    신중하게 이름을 선택합니다. 여기에 입력한 이름은 음성 합성 요청에서 음성을 지정할 때 SSML 입력의 일부로 사용됩니다. 只允许使用字母、数字和几个标点符号，如-、\_和（"，"）。 为不同的语音模型使用不同的名称。

    **설명** 필드의 일반적인 용도는 모델을 만드는 데 사용된 데이터 세트의 이름을 기록하는 것입니다.

4.  从 "**选择定型数据**" 页中，选择一个或多个要用于定型的数据集。 提交最谈话之前，请检查其数量。 可以从任意数量的最谈话开始，为 en-us 和 zh-chs 语音模型。 对于其他区域设置，你必须选择超过2000最谈话才能训练语音。

    > [!NOTE]
    > 将从训练中删除重复的音频名称。 请确保所选数据集不包含跨多个 .zip 文件的相同音频名称。

    > [!TIP]
    > 对于质量结果，需要使用同一发言人中的数据集。 当你为定型提交的数据集包含的总数小于6000个不同的最谈话时，你将通过统计参数合成技术来训练语音模型。 如果定型数据超过6000个不同最谈话的总数，则会开始使用串联合成技术进行训练。 通常，连接技术会导致更自然、更高保真的语音结果。 如果要使用最新的神经 TTS 技术来训练模型，该技术可产生与公开可用的[神经声音](language-support.md#neural-voices)等效的数字语音，[请联系自定义语音团队](https://go.microsoft.com/fwlink/?linkid=2108737)。

5.  单击 "**训练**" 开始创建语音模型。

定型表显示与这个新创建的模型相对应的新条目。 该表还显示状态： "正在处理"、"已成功" 和 "失败"。

显示的状态反映将数据集转换为语音模型的过程，如下所示。

| 상태 | 의미 |
| ----- | ------- |
| 처리 중 | 正在创建您的语音模型。 |
| 성공 | 你的语音模型已创建并可以部署。 |
| 실패 | 由于多种原因（例如不可见的数据问题或网络问题），您的语音模型在定型中已失败。 |

학습 시간은 처리되는 오디오 데이터의 양에 따라 달라집니다. 일반적인 시간 범위는 수백 개 발화에 해당하는 약 30분에서 20,000개 발화에 해당하는 40시간 정도입니다. 模型定型成功后，可以开始对其进行测试。

> [!NOTE]
> 免费订阅（F0）用户可以同时训练一种语音字体。 标准订阅（S0）用户可以同时训练三个声音。 이 제한에 도달하면 하나 이상의 음성 글꼴에 대한 학습이 완료될 때까지 기다린 후 다시 시도하세요.

> [!NOTE]
> 每个订阅允许的最大语音模型数量是为免费订阅（F0）用户使用10个模型，为标准订阅（S0）用户提供100。

如果您使用的是 "神经语音" 培训功能，则可以选择为适用于实时流式处理方案的优化模型定型，或对针对异步[长音频合成](long-audio-api.md)优化的高清神经模型进行定型。  

## <a name="test-your-voice-model"></a>测试语音模型

음성 글꼴을 성공적으로 작성한 후에는 사용을 위해 배포하기 전에 테스트할 수 있습니다.

1.  导航到**文本到语音 > 自定义语音 > 测试**。

2.  单击 "**添加测试**"。

3.  选择要测试的一个或多个模型。

4.  提供要语音朗读的文本。 如果您已选择一次测试多个模型，则相同的文本将用于测试不同的模型。

    > [!NOTE]
    > 텍스트의 언어는 음성 글꼴의 언어와 같아야 합니다. 只能测试已成功训练的模型。 此步骤只支持纯文本。

5.  **만들기**를 클릭합니다.

提交测试请求后，将返回到 "测试" 页。 이제 테이블에는 새 요청에 해당하는 항목과 익숙한 상태 열이 포함됩니다. 음성을 합성하는 데 몇 분 정도 걸릴 수 있습니다. 当 "状态" 列显示 "已**成功**" 时，可以播放音频，或下载文本输入（.txt 文件）和音频输出（.wav 文件），并进一步 audition 其质量。

您还可以在选择用于测试的每个模型的详细信息页中找到测试结果。 进入 "**培训**" 选项卡，然后单击模型名称以输入模型详细信息页。

## <a name="create-and-use-a-custom-voice-endpoint"></a>创建和使用自定义语音端点

음성 모델을 성공적으로 만들고 테스트한 후에는 사용자 지정 Text to Speech 엔드포인트로 배포합니다. 그런 다음, REST API를 통해 Text to Speech 요청을 수행할 때 일반적인 엔드포인트 대신 이 엔드포인트를 사용합니다. 自定义终结点只能由用于部署该字体的订阅调用。

若要创建新的自定义语音终结点，请转到**文本到语音 > 自定义语音 > 部署**。 选择 "**添加终结点**"，然后输入自定义终结点的**名称**和**描述**。 然后选择想要与此终结点关联的自定义语音模型。

单击 "**添加**" 按钮后，会在终结点表中看到新终结点的条目。 새 엔드포인트를 인스턴스화하는 데 몇 분 정도 걸릴 수 있습니다. 배포 상태가 **성공**이면 엔드포인트를 사용할 준비가 완료된 것입니다.

> [!NOTE]
> 免费订阅（F0）用户只能部署一个模型。 标准订阅（S0）用户最多可以创建50个终结点，每个终结点都有自己的自定义语音。

> [!NOTE]
> 若要使用自定义语音，必须指定语音模型名称，直接在 HTTP 请求中使用自定义 URI，并使用同一订阅来通过 TTS 服务的身份验证。

部署终结点后，终结点名称将显示为链接。 单击此链接可显示特定于你的终结点的信息，例如终结点密钥、终结点 URL 和示例代码。

엔드포인트의 온라인 테스트도 Custom Voice 포털을 통해 사용할 수 있습니다. 若要测试终结点，请从**终结点详细信息**页中选择 "**检查终结点**"。 엔드포인트 테스트 페이지가 나타납니다. 在文本框中输入要口述的文本（以纯文本[格式或 SSML 格式](speech-synthesis-markup.md)）。 **재생**을 선택하여 사용자 지정 음성 글꼴로 말해지는 텍스트를 들어봅니다. 此测试功能将针对自定义语音合成使用情况收费。

사용자 지정 엔드포인트는 텍스트 음성 변환 요청에 사용되는 표준 엔드포인트와 기능적으로 동일합니다. 자세한 내용은 [REST API](rest-text-to-speech.md)를 참조하세요.

## <a name="next-steps"></a>다음 단계

* [指南：录制语音示例](record-custom-voice-samples.md)
* [文本到语音 API 参考](rest-text-to-speech.md)
* [长音频 API](long-audio-api.md)
