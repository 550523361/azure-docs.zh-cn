---
title: 有关 Azure 中语音转文本服务的常见问题 | Microsoft Docs
description: 以下是有关语音转文本的最常见问题的解答。
services: cognitive-services
author: PanosPeriorellis
manager: onano
ms.service: cognitive-services
ms.component: custom-speech
ms.topic: article
ms.date: 06/11/2018
ms.author: panosper
ms.openlocfilehash: 543e8d6fb68a351dfe75c962debaf15eeb080a3f
ms.sourcegitcommit: 44fa77f66fb68e084d7175a3f07d269dcc04016f
ms.translationtype: HT
ms.contentlocale: zh-CN
ms.lasthandoff: 07/24/2018
ms.locfileid: "39223881"
---
# <a name="speech-to-text-frequently-asked-questions"></a>语音转文本常见问题解答

如果未在本常见问题解答中找到答案，请尝试在 [StackOverflow](https://stackoverflow.com/questions/tagged/project-oxford+or+microsoft-cognitive) 和 [UserVoice](https://cognitive.uservoice.com/) 的自定义语音服务社区中提问

## <a name="general"></a>常规

**问题**：基线模型和自定义语音转文本模型之间的区别是什么？

**解答**：基线模型已使用 Microsoft 拥有的数据定型，并且已部署在云中。 自定义模型允许用户调整模型，以便更好地适应具有特定环境噪音或语言的特定环境。 工厂大楼、汽车、嘈杂的街道需要适合的声学模型，而生物学、物理学、放射学、产品名称和自定义首字母缩略词等特定主题则需要适合的语言模型。

**问题**：如果想要使用基线模型，应从何处开始？

**解答**：首先，需要获取[订阅密钥](get-started.md)。 如果想要对预先部署的基线模型进行 REST 调用，请参阅[此处的详细信息](rest-apis.md)。 如果想要使用 WebSocket，请下载 [SDK](speech-sdk.md)

**问题**：是否始终需要生成自定义语音模型？

**解答**：否，如果应用程序使用通用日常语言，则无需自定义模型。 此外，如果应用程序用于背景噪音较少或无背景噪音的环境，也不需要自定义模型。 门户允许用户部署基线模型和自定义模型，并针对这些模型运行准确度测试。 用户可使用此功能来测量并比较基线模型和自定义模型的准确度。

**问题**：如何知道数据集或模型是否已处理完成？

**解答**：目前，表中的模型或数据集状态是唯一能知道的方法。
处理完成后，状态将为“成功”。

**问题**：可否创建多个模型？

**解答**：集合中的模型数量没有限制。

**问题**：我意识到自己犯了一个错误。 如何取消正在进行的数据导入或模型创建？ 

**解答**：当前无法回退声学或语言适应过程。 导入的数据和模型在处于终端状态后可被删除。

**问题**：搜索和听写模型与对话模型之间的区别是什么？

**解答**：语音服务中有多个基线模型可供选择。 “对话”模型适用于识别以对话形式说出的语音。 此模型是理想的转录调用，而搜索和听写是理想的语音触发应用。 通用是一个新模型，旨在解决这两种情况。

**问题**：是否可以更新现有模型（模型堆叠）？

**解答**：无法更新现有模型。 一种暂时的解决方法是将旧数据集与新数据集合并，然后重新适应。

必须将新旧数据集合在单个 .zip 文件（如果是声学数据）或 .txt 文件（如果是语言数据）中。 适应完成后，需要取消部署新更新的模型，获取新的终结点

**问题**：如果部署的模型所需并发高于门户中提供的，应该如何操作？ 

**解答**：以 20 个并发请求为增量纵向扩展模型。 

如果需要更大的规模，请与我们联系。

**问题**：是否可以下载模型并在本地运行？

**解答**：无法下载模型并在本地执行。

**问题**：是否记录了我的请求？

**解答**：在创建部署期间，可选择关闭跟踪，此时不会记录音频或听录。 否则，通常会将请求记录在 Azure 中并安全存储。 如果还有禁止使用自定义语音服务的进一步隐私问题，请与某个支持渠道联系。

## <a name="importing-data"></a>导入数据

**问题**：数据集的大小限制是多少？ 为什么？ 

**解答**：由于 HTTP 上传的文件大小受限，因此数据集当前的大小上限为 2 GB。 

**问题**：是否可以压缩文本文件，以便上传更大的文本文件？ 

**解答**：否，当前仅允许使用未压缩的文本文件。

**问题**：数据报告显示存在失败的话语。 问题出在哪里？

**解答**：未能 100% 上传文件中的话语并不是什么问题。
如果成功导入了声学或语言数据集中的绝大多数话语（如 95% 以上的话语），则该数据集可用。 但是，建议尝试了解话语失败的原因并修复问题。 大多数常见问题（如格式设置错误）很容易修复。 

## <a name="creating-am"></a>创建 AM

**问题**：需要多少声学数据？

**解答**：建议开始时先使用 30 分钟到一小时的声学数据。

**问题**：应收集哪些数据？

**解答**：收集尽可能接近于应用程序方案和用例的数据。
数据收集应在设备、环境和说话人类型方面与目标应用程序和用户匹配。 一般而言，应从尽可能广泛的说话人中收集数据。 

**问题**：应如何收集数据？ 

**解答**：可以创建独立的数据收集应用程序，或使用现成的录音软件。
还可以创建记录音频数据并使用该数据的应用程序版本。 

**问题**：是否需要自行转录适应数据？ 

**解答**：是的！ 可以自行转录或使用专业听录服务进行转录。 有些用户更喜欢使用专业听录器，而其他用户使用众包或自己进行听录。

## <a name="accuracy-testing"></a>精确度测试

**问题**：是否可以使用自定义语言模型执行自定义声学模型的离线测试？

**解答**：可以，只需在设置离线测试时，在下拉菜单中选择自定义语言模型即可

**问题**：是否可以使用自定义声学模型执行自定义语言模型的离线测试？

**解答**：可以，只需在设置离线测试时，在下拉菜单中选择自定义声学模型即可。

**问题**：什么是字错误率 (WER) 以及如何计算此错误率？

**解答**：字错误率 (WER) 是语音识别的评估指标。 它由错误总数（包括插入、删除和替换）除以引用听录中的总字数得出。 [此处](https://en.wikipedia.org/wiki/Word_error_rate)提供了更多详细信息。

**问题**：如何确定准确度测试的结果是否良好？

**解答**：测试结果对基线模型和自定义模型进行了比较。
应以超越基线模型为目标，使自定义模型变得有价值。

**问题**：如何计算出基础模型的字错误率，以便了解是否有所改进？ 

**解答**：离线测试结果显示了基线模型的准确度、自定义模型的准确度，以及与基线相比的改进情况。

## <a name="creating-lm"></a>创建 LM

**问题**：需要上传多少文本数据？

**解答**：这取决于应用程序中使用的词汇和短语与初始语言模型存在多大差异。 对于所有新字词，请尽可能多地提供这些字的使用示例，这一点非常有用。 对于应用程序中使用的常用短语，在语言数据中包括短语也非常有用，因为这也会通知系统侦听这些术语。 语言数据集中具有至少 100 句话语（通常几百句）或更多话语是很常见的。 另外，如果某些类型的查询比其他类型更加常用，则可以在数据集中插入常用查询的多个副本。

**问题**：是否可以只上传字词列表？

**解答**：上传字词列表仅将字词添加到词汇中，但不会告知系统这些字词通常如何使用。
通过提供完整或部分话语（用户很可能会说的句子或短语），语言模型可以学习这些新字词及其用法。 自定义语言模型不仅适用于获取系统中的新字词，而且还可用于调整应用程序的已知字词概率。 提供完整话语可帮助系统更好地学习。 

## <a name="next-steps"></a>后续步骤

* [故障排除](troubleshooting.md)
* [发行说明](releasenotes.md)
