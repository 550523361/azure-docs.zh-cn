---
title: 评估模型：模块参考
titleSuffix: Azure Machine Learning
description: 了解如何使用 Azure 机器学习中的“评估模型”模块来度量已训练模型的准确度。
services: machine-learning
ms.service: machine-learning
ms.subservice: core
ms.topic: reference
author: likebupt
ms.author: keli19
ms.date: 02/24/2020
ms.openlocfilehash: c1bcbb6a368c9c80f968c48c1a6e0bc6c95133d6
ms.sourcegitcommit: 2ec4b3d0bad7dc0071400c2a2264399e4fe34897
ms.translationtype: MT
ms.contentlocale: zh-CN
ms.lasthandoff: 03/28/2020
ms.locfileid: "79456398"
---
# <a name="evaluate-model-module"></a>“评估模型”模块

本文介绍 Azure 机器学习设计器（预览版）中的一个模块。

使用此模块可以度量已训练模型的准确度。 提供包含通过模型生成的评分的数据集后，“评估模型”模块将计算一组符合行业标准的评估指标。****
  
 “评估模型”返回的指标取决于评估的模型类型：****  
  
-   **分类模型**    
-   **回归模型**  
-   **聚类模型**  


> [!TIP]
> 如果您是模型评估的新产品，我们建议您使用 Stephen Elston 博士的视频系列，作为 EdX[机器学习课程](https://blogs.technet.microsoft.com/machinelearning/2015/09/08/new-edx-course-data-science-machine-learning-essentials/)的一部分。 


可通过三种方式使用“评估模型”模块：****

+ 针对训练数据生成评分，然后基于这些评分评估模型
+ 在模型中生成评分，但将这些评分与保留的测试集中的评分进行比较
+ 使用相同的数据集比较两个不同但相关的模型的评分

## <a name="use-the-training-data"></a>使用训练数据

若要评估某个模型，必须连接包含一组输入列和评分的数据集。  如果没有其他可用数据，可以使用原始数据集。

1. 将[评分模型](./score-model.md)的“已评分数据集”输出连接到“评估模型”的输入。******** 
2. 单击“评估模型”模块，并运行管道来生成评分。****

## <a name="use-testing-data"></a>使用测试数据

机器学习的一种常用方案是使用[拆分](./split-data.md)模块或[分区和采样](./partition-and-sample.md)模块，将原始数据集划分成训练和测试数据集。 

1. 将[评分模型](score-model.md)的“已评分数据集”输出连接到“评估模型”的输入。******** 
2. 将包含测试数据的“拆分数据”模块的输出连接到“评估模型”右侧的输入。****
2. 单击“评估模型”模块，选择“运行所选项”来生成评分。********

## <a name="compare-scores-from-two-models"></a>比较两个模型的评分

还可以将第二组评分连接到“评估模型”。****  评分可以是包含已知结果的共享评估集，也可以是不同模型针对相同数据提供的一组结果。

此功能非常有用，因为它可以让你轻松比较两个不同模型针对相同数据提供的结果。 或者，可以比较两个不同运行使用不同参数针对相同数据提供的评分。

1. 将[评分模型](score-model.md)的“已评分数据集”输出连接到“评估模型”的输入。******** 
2. 将第二个模型的“评分模型”模块的输出连接到“评估模型”右侧的输入。****
3. 提交管道。

## <a name="results"></a>结果

运行**评估模型**后，右键单击模块并选择**可视化评估结果**以查看结果。

如果将数据集连接到“评估模型”的两个输入，结果将包含两个数据集或两个模型的指标。****
附加到左侧端口的模型或数据先显示在报告中，其后是附加到右侧端口的数据集或模型的指标。  

例如，下图显示了基于相同数据但不同参数生成的两个聚类模型的结果比较。  

![比较2模型](media/module/evaluate-2-models.png)  

由于这是一个聚类模型，因此评估结果与比较两个回归模型的评分或比较两个分类模型时出现的结果不同。 不过，提供的结果在总体上是相同的。 

## <a name="metrics"></a>指标

本部分介绍针对支持与“评估模型”配合使用的特定模型类型返回的指标：****

+ [分类模型](#metrics-for-classification-models)
+ [回归模型](#metrics-for-regression-models)
+ [聚类模型](#metrics-for-clustering-models)

### <a name="metrics-for-classification-models"></a> 分类模型的指标

评估分类模型时，将报告以下指标。
  
-   “准确度”以真实结果数与案例总数之比的形式度量分类模型的好坏。****  
  
-   “精准率”是真实结果与所有正面结果之比。****  
  
-   “召回率”是模型返回的所有正确结果的小数。****  
  
-   “F 评分”计算为精准率与召回率的加权平均值，介于 0 和 1 之间，理想的 F 评分值为 1。****  
  
-   “AUC”度量绘制的曲线下面的面积（在 y 轴上绘制真报率，在 x 轴上绘制误报率）。**** 此指标非常有用，因为它提供单个数字让你比较不同类型的模型。  
  
- “平均对数损失”是用于表示错误结果的惩罚的单个评分。**** 它计算为以下两个概率分布之差 – 真实分布，以及模型中的分布。  
  
- “训练对数损失”是表示分类器相比随机预测的优势的单个评分。**** 对数损失通过将模型输出的概率与标签中的已知值（真实值）进行比较，来度量模型的不确定性。 我们希望最大程度地减小整个模型的对数损失。

### <a name="metrics-for-regression-models"></a> 回归模型的指标
 
针对回归模型返回的指标旨在估计误差量。  如果观测值与预测值之间的差很小，则认为模型能够很好地拟合数据。 不过，查看残差模式（任何一个预测点与其对应实际值之间的差）可以很好地判断模型中的潜在偏差。  
  
 将报告以下指标来评估回归模型。
  
- “平均绝对误差 (MAE)”度量预测结果与实际结果的接近程度；因此，评分越低越好。****  
  
- “均方根误差 (RMSE)”创建单个值用于汇总模型中的误差。**** 求差的平方时，指标将忽略过预测与欠预测之差。  
  
- “相对绝对误差 (RAE)”是预期值与实际值之间的相对绝对差；之所以是相对的，是因为平均差将除以算术平均值。****  
  
- 类似地，“相对平方误差 (RSE)”除以实际值的总平方误差，以此规范化预测值的总平方误差。****  
  

  
- “决定系数”（通常称为 R<sup>2</sup>）表示模型的预测能力，值为 0 到 1。**** 如果为 0，则模型是随机的（不解释任何信息）；1 表示完美拟合。 不过，在解释 R<sup>2</sup> 值时请小心，因为低值可能完全正常，而高值可能是可疑的。

###  <a name="metrics-for-clustering-models"></a>聚类模型的指标

由于聚类模型在许多方面与分类和回归模型存在显著差异，[因此评估模型](evaluate-model.md)还会为聚类模型返回一组不同的统计信息。  
  
 为聚类模型返回的统计信息描述分配给每个群集的数据点数、群集之间的分离量以及数据点在每个群集中的聚束紧密程度。  
  
 聚类模型的统计信息在整个数据集上求平均值，其他行包含每个群集的统计信息。  
  
报告以下指标用于评估聚类模型。
    
-   列中的分数"**与其他中心的平均距离**"表示群集中每个点的平均值与所有其他群集的质心的距离。   

-   列中的分数"**与群集中心的平均距离**"表示群集中所有点的接近于该群集的质心。  
  
-   "**点数"** 列显示分配给每个群集的数据点数，以及任何群集中数据点的总数量。  
  
     如果分配给群集的数据点数小于可用数据点总数，则意味着无法将数据点分配给群集。  
  
-   列中的分数"**最大距离到聚类中心**"表示每个点与该点聚类的质心之间的距离之和。  
  
     如果此数字较高，则可能意味着群集分布广泛。 您应该查看此统计信息以及**群集中心的平均距离**，以确定群集的分布。   

-   结果各部分底部**的综合评估**分数列出了该特定模型中创建的群集的平均分数。  
  

## <a name="next-steps"></a>后续步骤

参阅 Azure 机器学习[可用的模块集](module-reference.md)。 