---
title: 隐性 Dirichlet 分配
titleSuffix: Azure Machine Learning
description: 了解如何使用潜在的 "Dirichlet 分配" 模块将其他未分类的文本分组为多个类别。
services: machine-learning
ms.service: machine-learning
ms.subservice: core
ms.topic: reference
author: likebupt
ms.author: keli19
ms.date: 03/11/2020
ms.openlocfilehash: 1384491489c175ffc338f80a99aa8d5050f835d5
ms.sourcegitcommit: 849bb1729b89d075eed579aa36395bf4d29f3bd9
ms.translationtype: MT
ms.contentlocale: zh-CN
ms.lasthandoff: 04/28/2020
ms.locfileid: "80109220"
---
# <a name="latent-dirichlet-allocation"></a>隐性 Dirichlet 分配

本文介绍如何使用 Azure 机器学习设计器（预览版）中的**潜在 Dirichlet 分配**模块将其他未分类文本分组为多个类别。 

潜在的 Dirichlet 分配（LDA）通常用于自然语言处理（NLP）以查找类似的文本。 另一种常见术语是*主题建模*。

此模块采用文本列，并生成以下输出：

+ 源文本，以及每个类别的分数

+ 功能矩阵，其中包含每个类别的已提取术语和系数

+ 转换，你可以保存并重新应用于用作输入的新文本

此模块使用 scikit-learn 库。 有关 scikit-learn 的详细信息，请参阅 [GitHub 存储库，其中包含有关算法的教程和说明。

### <a name="more-about-latent-dirichlet-allocation-lda"></a>有关潜在 Dirichlet 分配的详细信息（LDA）

一般而言，LDA 不是每个 se 分类的方法，而是使用生成方法。 这意味着不需要提供已知的类标签，然后推断模式。  相反，该算法将生成用于标识主题组的概率模型。 您可以使用概率模型对现有定型事例或您作为输入提供给模型的新事例进行分类。

生成模型可以更好地使用，因为它可以避免对文本和类别之间的关系进行任何严格假设，并仅使用单词到数学模型的分布。

+ 本白皮书中讨论了理论，如 PDF 下载：[潜在 Dirichlet 分配： Blei、Ng 和约旦](https://ai.stanford.edu/~ang/papers/nips01-lda.pdf)

+ 此模块中的实现基于用于 LDA 的[scikit-learn 库](https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/decomposition/_lda.py)。

有关详细信息，请参阅[技术说明](#technical-notes)部分。

## <a name="how-to-configure-latent-dirichlet-allocation"></a>如何配置潜在的 Dirichlet 分配

此模块需要一个数据集，该数据集包含一列 raw 或预处理文本。

1. 将**潜在的 Dirichlet 分配**模块添加到管道。

2. 作为模块的输入，提供包含一个或多个文本列的数据集。

3. 对于 "**目标列**"，选择一个或多个包含要分析的文本的列。

    您可以选择多个列，但它们必须是字符串数据类型。

    通常，由于 LDA 会从文本创建大型特征矩阵，因此通常会分析单个文本列。

4. 对于 "**要建模的主题数**"，请键入一个介于1和1000之间的整数，该整数指示要从输入文本派生的类别或主题的数量。

    默认情况下，将创建5个主题。

5. 对于**n 语法**，指定哈希处理期间生成的 n 元语法的最大长度。

    默认值为2，表示同时生成二元语法和获得单元语法。

6. 选择 "**规范化**" 选项将输出值转换为概率。 因此，输出和功能数据集中的值将按如下方式转换，而不是将转换后的值表示为整数：

    + 数据集中的值将表示为概率`P(topic|document)`。

    + 功能主题矩阵中的值将表示为概率`P(word|topic)`。

    > [!NOTE] 
    > 在 Azure 机器学习设计器（预览版）中，由于我们所基于的库（scikit-learn）不再支持版本0.19 中的非规范化*doc_topic_distr*输出，因此，在此模块中，**规范化**参数只能应用于**功能主题矩阵**输出，**转换的数据集**输出始终规范化。

7. 选择选项 "**显示所有选项**"，然后将其设置为 "TRUE"，以便查看并设置其他高级参数。

    这些参数特定于 LDA 的 scikit-learn 实现。 有关 LDA 的一些不错的教程，请参阅 scikit-learn 和官方[scikit-learn-学习文档](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html)。

    + **Rho 参数**。 为主题分发的稀疏度提供前面的概率。 对应于 spark-sklearn 的`topic_word_prior`参数。 如果希望单词的分布是平面的，则使用值 1;也就是说，所有词都是 equiprobable。 如果认为大多数单词显示稀疏，则可以将其设置为较小的值。

    + **Alpha 参数**。 为每个文档的 "主题权重" 的稀疏度指定先前的概率。  对应于 spark-sklearn 的`doc_topic_prior`参数。

    + **估计的文档数**。 键入一个数字，该数字表示要处理的文档数（行）的最佳估计值。 这样，模块就可以分配足够大小的哈希表。  对应于 scikit-learn `total_samples`中的参数。

    + **批处理的大小**。 键入一个数字，用于指示要在发送到 LDA 模型的每批文本中包含多少行。 对应于 scikit-learn `batch_size`中的参数。

    + **学习更新计划中使用的迭代的初始值**。 指定在联机学习中 downweights 学习率的开始值。 对应于 scikit-learn `learning_offset`中的参数。

    + **更新过程中应用于迭代的电源**。 指示应用于迭代数的电源级别，以便在联机更新期间控制学习速率。 对应于 scikit-learn `learning_decay`中的参数。

    + **通过数据的次数**。 指定算法将在数据上循环的最大次数。 对应于 scikit-learn `max_iter`中的参数。

8. 如果要在初始传递中创建 n 语法列表，请在对文本进行分类之前，选择选项 "**生成字典 of ngrams** " 或 " **ngrams 的生成字典**"。

    如果事先创建了初始字典，则可以在以后查看该模型时使用该字典。 能够将结果映射到文本而不是数字索引通常更容易解释。 但是，保存字典会花费较长的时间，并使用额外的存储。

9. 对于 " **ngram 字典的最大大小**"，请键入可在 n 语法字典中创建的总行数。

    此选项对于控制字典的大小很有用。 但是，如果输入中的 ngrams 数超过此大小，则可能发生冲突。

10. 提交管道。 LDA 模块使用 Bayes 定理来确定哪些主题可能与单个字词相关联。 字词不与任何主题或组完全关联;相反，每个 n 语法都具有与任何发现的类相关联的已了解的概率。

## <a name="results"></a>结果

模块有两个输出：

+ **转换后的数据集**：包含输入文本和指定数量的发现的类别，以及每个类别的每个文本示例的分数。

+ **功能主题矩阵**：最左侧的列包含提取的文本功能，每个类别都有一列包含该类别中该功能的分数。


### <a name="lda-transformation"></a>LDA 转换

此模块还输出将 LDA 应用于数据集的*LDA 转换*。

您可以通过在模块的右窗格中的 "**输出 + 日志**" 选项卡下注册数据集来保存此转换，并将其重新用于其他数据集。 如果你已在大型语料库上定型并想要重复使用系数或类别，这可能很有用。

### <a name="refining-an-lda-model-or-results"></a>优化 LDA 模型或结果

通常，您不能创建可满足所有需求的单个 LDA 模型，甚至为一个任务设计的模型也可能需要多次迭代才能提高准确性。 建议您尝试所有这些方法来改进模型：

+ 更改模型参数
+ 使用可视化效果了解结果
+ 获取主题专家的反馈，以确定所生成的主题是否很有用。

定性度量值也可用于评估结果。 若要评估主题建模结果，请考虑：

+ 准确性-类似的项目真的相似？
+ 多样性-在业务问题需要时，模型是否可以在类似项之间进行区分？
+ 可伸缩性-它是适用于各种文本类别还是仅适用于窄目标域？

通常，可以使用自然语言处理来清理、汇总和简化文本或对文本进行分类，从而改善基于 LDA 的模型的准确性。 例如，以下技术（Azure 机器学习中的所有支持）都可以提高分类准确度：

+ 停止词删除

+ 大小写规范化

+ 词形还原或词干

+ 命名实体识别

有关详细信息，请参阅[预处理文本](preprocess-text.md)。

在设计器中，还可以使用 R 或 Python 库进行文本处理：[执行 r 脚本](execute-r-script.md)，[执行 Python 脚本](execute-python-script.md)



## <a name="technical-notes"></a>技术说明

本部分包含实现详情、使用技巧和常见问题解答。

### <a name="implementation-details"></a>实现详细信息

默认情况下，转换后的数据集和功能-主题矩阵的输出分布将规范化为概率。

+ 转换后的数据集标准化为给定文档的条件主题的条件概率。 在这种情况下，每行的总和等于1。

+ 功能主题矩阵标准化为给定主题的条件的条件概率。 在这种情况下，每列的总和等于1。

> [!TIP]
> 有时，模块可能返回一个空主题，这通常是由于算法的伪随机初始化导致的。  如果发生这种情况，你可以尝试更改相关参数，如 N 语法字典的最大大小或用于功能哈希的位数。

### <a name="lda-and-topic-modeling"></a>LDA 和主题建模

潜在的 Dirichlet 分配（LDA）通常用于*基于内容的主题建模*，这基本上意味着从未分类文本学习类别。 在基于内容的主题建模中，主题是针对单词的分布。

例如，假设您提供了一语料库包含许多产品的客户评论。 许多客户在一段时间内提交的评论文本将包含多个条款，其中一些术语在多个主题中使用。

LDA 进程标识的**主题**可能代表单个产品 A 的评论，或者它可能代表一组产品评论。 对于 LDA，主题本身就是一组单词的一段时间内的概率分布。

术语很少适用于任何一种产品，但可以引用其他产品，或者是适用于所有内容的一般术语（"好"、"工作"）。 其他字词可能是干扰词。  但是，必须了解的是，LDA 方法不声称捕获 universe 中的所有字词，也不能了解字词的关联方式，这一点与共同发生的概率无关。 它只能对在目标域中使用的单词进行分组。

计算字词索引后，将使用基于距离的相似性度量值来比较各个行的文本，以确定两个文本段是否彼此类似。  例如，你可能会发现该产品有多个强关联的名称。 或者，您可能会发现，强负术语通常与特定产品关联。 您可以使用相似性度量值来标识相关的字词并创建建议。

###  <a name="module-parameters"></a>模块参数

|名称|类型|范围|可选|默认|说明|  
|----------|----------|-----------|--------------|-------------|-----------------|  
|目标列|列选择||必选|StringFeature|目标列名称或索引|  
|要建模的主题数|Integer|[1; 1000]|必选|5|针对 N 个主题为文档分发建模|  
|N 元语法|Integer|[1; 10]|必选|2|哈希处理期间生成的 N 元语法的顺序|  
|进行|布尔值|是或否|必选|true|将输出规范化为概率。  转换后的数据集将为 P （主题&#124;文档），并且功能主题矩阵将为 P （word&#124;主题）|  
|显示所有选项|布尔值|是或否|必选|False|显示特定于 scikit-learn 的其他参数-online LDA|  
|Rho 参数|Float|[0.00001; 1.0]|当选中 "**显示所有选项**" 复选框时适用|0.01|主题 word 以前的分发|  
|Alpha 参数|Float|[0.00001; 1.0]|当选中 "**显示所有选项**" 复选框时适用|0.01|发布前的文档主题|  
|估计的文档数|Integer|[1;int.MaxValue]|当选中 "**显示所有选项**" 复选框时适用|1000|估计的文档数（与 total_samples 参数对应）|  
|批大小|Integer|[1; 1024]|当选中 "**显示所有选项**" 复选框时适用|32|批大小|  
|学习速率更新计划中使用的迭代初始值|Integer|[0; int。Timespan.maxvalue|当选中 "**显示所有选项**" 复选框时适用|0|用于提前迭代的 downweights 学习率的初始值。 对应于 learning_offset 参数|  
|更新过程中应用于迭代的电源|Float|[0.0; 1.0]|当选中 "**显示所有选项**" 复选框时适用|0.5|为了控制学习速度，将电源应用到迭代计数。 对应于 learning_decay 参数 |  
|训练迭代数|Integer|[1; 1024]|当选中 "**显示所有选项**" 复选框时适用|25|训练迭代数|  
|Ngrams 的生成字典|布尔值|是或否|当*未*选中 "**显示所有选项**" 复选框时应用|True|在计算 LDA 之前生成 ngrams 字典。 适用于模型检查和解释|  
|Ngram 字典的最大大小|Integer|[1;int.MaxValue]|当 ngrams 的选项**生成字典**为 True 时适用|20000|Ngrams 字典的最大大小。 如果输入中的令牌数超过此大小，则可能发生冲突|  
|用于特征哈希的位数|Integer|[1; 31]|当*未*选择 "**显示所有选项**" 复选框并且**Ngrams 的生成字典**为 False 时适用|12|用于特征哈希的位数| 
|LDA 之前的 ngrams 生成字典|布尔值|是或否|当选中 "**显示所有选项**" 复选框时适用|True|在 LDA 之前生成 ngrams 字典。 适用于模型检查和解释|  
|字典中 ngrams 的最大数目|Integer|[1;int.MaxValue]|当选中 "**显示所有选项**" 复选框并且 "ngrams 的选项"**生成字典**为 True 时适用。|20000|字典的最大大小。 如果输入中的令牌数超过此大小，则可能发生冲突|  
|哈希位数|Integer|[1; 31]|当选中 "**显示所有选项**" 复选框并且 "ngrams 的选项"**生成字典**为 False 时应用|12|功能哈希期间要使用的位数|   


## <a name="next-steps"></a>后续步骤

参阅 Azure 机器学习[可用的模块集](module-reference.md)。   
有关特定于模块的错误列表，请参阅[设计器的异常和错误代码](designer-error-codes.md)。
