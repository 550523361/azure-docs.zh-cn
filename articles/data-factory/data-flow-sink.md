---
title: 设置 Azure 数据工厂中映射 Data Flow 功能的接收器转换
description: 了解如何设置映射在数据流中的接收器转换。
author: kromerm
ms.author: makromer
ms.service: data-factory
ms.topic: conceptual
ms.date: 02/03/2019
ms.openlocfilehash: 4341cbb0e24330d535f5211c088f0068eab33af7
ms.sourcegitcommit: d4dfbc34a1f03488e1b7bc5e711a11b72c717ada
ms.translationtype: MT
ms.contentlocale: zh-CN
ms.lasthandoff: 06/13/2019
ms.locfileid: "65596265"
---
# <a name="sink-transformation-for-a-data-flow"></a>接收器数据流的转换

[!INCLUDE [notes](../../includes/data-factory-data-flow-preview.md)]

转换数据的流后，您可以到目标数据集接收器数据。 在接收器转换中，选择该目标的输出数据的数据集定义。 您可以有很多接收器转换，因为需要数据的流。

到帐户进行架构偏差和传入数据中的更改而无需在输出数据集中定义的架构文件夹到接收器的输出数据。 可以还考虑了列的更改在源中通过选择**允许架构偏差**源中。 然后自动映射所有字段在接收器中。

![包括自动映射选项的接收器选项卡上的选项](media/data-flow/sink1.png "接收器 1")

要接收传入的所有字段，开启**自动映射**。 若要选择的字段到接收器到目标，或若要更改的目标处的字段的名称，将关闭**自动映射**。 然后打开**映射**选项卡可将输出字段。

![在映射选项卡上的选项](media/data-flow/sink2.png "接收器 2")

## <a name="output"></a>输出 
对于 Azure Blob 存储或 Data Lake 存储接收器类型，输出到的文件夹已转换的数据。 Spark 生成已分区的输出接收器转换所使用的分区方案基于的数据文件。 

您可以设置从分区方案**优化**选项卡。如果你想要将输出合并到单个文件的数据工厂，请选择**单个分区**。

![在优化选项卡上的选项](media/data-flow/opt001.png "接收器选项")

## <a name="field-mapping"></a>字段映射

上**映射**选项卡的接收器转换中，可以传入的列映射在左侧到右侧的目标。 时对文件接收器的数据流，数据工厂将始终写入新文件的文件夹。 当您映射到数据库数据集时，可以生成新表，需要通过设置使用此架构**保存策略**到**覆盖**。 或在现有表中插入新行，然后将字段映射到现有架构。 

![映射选项卡](media/data-flow/sink2.png "接收器")

在映射表中，你可以多选要链接的多个列，解除链接多个列，或将多个行映射到相同的列名称。

若要始终将传入组字段映射到目标，原样，而若要完全接受灵活的架构定义，请选择**允许架构偏差**。

![映射选项卡，其中显示字段映射到数据集中的列](media/data-flow/multi1.png "多个选项")

若要重置列映射，请选择**重新映射**。

![接收器选项卡](media/data-flow/sink1.png "一个接收器")

选择**验证架构**失败接收器，如果架构发生更改。

选择**清除文件夹**写入该目标文件夹中的目标文件之前截断接收器文件夹的内容。

## <a name="file-name-options"></a>文件名选项

设置文件命名： 

   * **默认**：可让 Spark 将名称文件基于部分默认值。
   * **模式**:输入输出文件的一种模式。 例如，**贷款 [n]** 将创建 loans1.csv、 loans2.csv，等等。
   * **每个分区**:输入每个分区的一个文件名。
   * **列中的数据作为**:设置输出文件为列的值。
   * **输出到单个文件**:使用此选项，ADF 将将已分区的输出文件合并到单个命名的文件。 若要使用此选项，你的数据集应解析为文件夹名称。 此外，请注意此合并操作可能会失败可能基于节点大小。

> [!NOTE]
> 文件操作开始，仅当正在运行的执行数据流的活动时。 它们不在数据流动调试模式下启动。

## <a name="database-options"></a>数据库选项

选择数据库设置：

* **更新方法**:默认值是允许插入。 清除**允许插入**如果你想要停止从你的源中插入新行。 若要更新，更新插入或删除行，首先将 alter 行转换添加到这些操作的标记行。 
* **重新创建表**:删除或创建目标表，然后数据流完成。
* **截断表**:数据流完成之前，请从目标表中删除所有行。
* **批大小**：输入一个数字以将写入内容装桶成区块。 对大型数据加载使用此选项。 
* **启用暂存**:使用 PolyBase 加载 Azure 数据仓库作为接收器数据集时。

![显示 SQL 接收器选项的设置选项卡](media/data-flow/alter-row2.png "SQL 选项")

> [!NOTE]
> 在数据流中，可以指示要在目标数据库中创建新的表定义的数据工厂。 若要创建表定义，请设置接收器转换具有新的表名称中的数据集。 在 SQL 数据集，下面的表名称，选择**编辑**并输入新的表名称。 然后，在接收器转换中，开启**允许架构偏差**。 设置**导入架构**到**None**。

![SQL 数据集设置，显示在何处编辑表名](media/data-flow/dataset2.png "SQL 架构")

> [!NOTE]
> 在更新或删除数据库接收器中的行，必须设置的键列。 此设置允许更改行转换以确定在数据移动库 (DML) 中的唯一行。

## <a name="next-steps"></a>后续步骤

现在，已创建数据的流，添加[到你的管道的数据流活动](concepts-data-flow-overview.md)。
