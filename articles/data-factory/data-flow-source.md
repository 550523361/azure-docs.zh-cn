---
title: 在 Azure 数据工厂的映射数据流功能中设置源转换
description: 了解如何在映射数据流中设置源转换。
author: kromerm
ms.author: makromer
ms.service: data-factory
ms.topic: conceptual
ms.date: 02/12/2019
ms.openlocfilehash: 974ece9cd035ae29ada38f34b7933d86f682194f
ms.sourcegitcommit: 800f961318021ce920ecd423ff427e69cbe43a54
ms.translationtype: MT
ms.contentlocale: zh-CN
ms.lasthandoff: 07/31/2019
ms.locfileid: "68696235"
---
# <a name="source-transformation-for-mapping-data-flow"></a>映射数据流的源转换 

[!INCLUDE [notes](../../includes/data-factory-data-flow-preview.md)]

源转换为数据流配置数据源。 数据流可以包含多个源转换。 在设计数据流时, 始终以源转换开头。

每个数据流需要至少一个源转换。 根据需要添加任意多个源以完成数据转换。 您可以将这些源与联接转换或联合转换一起联接。

> [!NOTE]
> 调试数据流时, 将使用采样设置或调试源限制从源读取数据。 若要将数据写入接收器, 必须从管道数据流活动运行数据流。 

!["源设置" 选项卡上的源转换选项](media/data-flow/source.png "源")

将数据流源转换与恰好一个数据工厂数据集相关联。 数据集定义要写入或读取的数据的形状和位置。 您可以使用源中的通配符和文件列表一次处理多个文件。

使用**通配符模式**选项将指示 ADF 通过单个源转换循环遍历每个匹配的文件夹和文件。 这是在单个流中处理多个文件的一种非常有效的方式。 若要跟踪当前正在处理的文件名, 请在源选项中为 "要存储文件名的列" 字段设置字段名称。

> [!NOTE]
> 设置多个通配符匹配模式, 并在现有通配符模式旁边加上 + 符号, 以添加更多通配符规则。

## <a name="data-flow-staging-areas"></a>数据流暂存区域
数据流适用于所有在 Azure 中的*临时*数据集。 在转换数据时, 使用这些数据集进行过渡。 

数据工厂有权访问将近80本机连接器。 若要在数据流中包含其他源中的数据, 请使用 "复制活动" 工具将这些数据暂存到其中一个数据流数据集暂存区域。

## <a name="options"></a>选项

选择数据的架构和采样选项。

### <a name="schema-drift"></a>架构偏差
[在无](concepts-data-flow-schema-drift.md)需显式定义列更改的情况下, ADF 可以在数据流中本机处理灵活的架构。

* 如果源列经常更改, 请选择 "**允许架构偏移**"。 此设置允许所有传入的源字段流过到接收器的转换。

* 选择 "**推断偏移列类型**" 将指示 ADF 为发现的每个新列定义数据类型。 关闭此功能后, ADF 将采用字符串。

### <a name="validate-schema"></a>验证架构

如果源数据的传入版本与定义的架构不匹配, 则数据流将无法运行。

![公共源设置, 显示用于验证架构、允许架构偏移和采样的选项](media/data-flow/source1.png "公共源 1")

### <a name="sample-the-data"></a>数据采样
启用**采样**以限制源中的行数。 当你在源中测试数据或对数据进行采样以便进行调试时, 请使用此设置。

## <a name="define-schema"></a>定义架构

如果源文件不是强类型文件 (例如, 平面文件而不是 Parquet 文件), 请在此处为源转换中的每个字段定义数据类型。  

!["定义架构" 选项卡上的源转换设置](media/data-flow/source2.png "源 2")

以后可以在 select 转换中更改列名。 使用派生列转换来更改数据类型。 对于强类型化源, 您可以在以后的选择转换中修改数据类型。 

![Select 转换中的数据类型](media/data-flow/source003.png "数据类型")

### <a name="optimize-the-source-transformation"></a>优化源转换

在源转换的 "**优化**" 选项卡上, 可能会看到**源**分区类型。 仅当你的源是 Azure SQL 数据库时, 此选项才可用。 这是因为数据工厂会尝试建立并行连接, 以针对 SQL 数据库源运行大型查询。

![源分区设置](media/data-flow/sourcepart3.png "分区")

不需要对 SQL 数据库源上的数据进行分区, 但分区对于大型查询很有用。 您可以将分区基于列或查询。

### <a name="use-a-column-to-partition-data"></a>使用列对数据进行分区

从源表中, 选择要进行分区的列。 同时设置分区数。

### <a name="use-a-query-to-partition-data"></a>使用查询对数据进行分区

您可以选择基于查询对连接进行分区。 只需输入 WHERE 谓词的内容即可。 例如, 输入 year > 1980。

## <a name="source-file-management"></a>源文件管理

选择 "设置" 以管理源中的文件。 

![新源设置](media/data-flow/source2.png "新设置")

* **通配符路径**:从源容器中, 选择与模式匹配的一系列文件。 此设置将重写数据集定义中的任何文件。

通配符示例:

* ```*```表示任意字符集
* ```**```表示递归目录嵌套
* ```?```替换一个字符
* ```[]```匹配括号中的一个或多个字符

* ```/data/sales/**/*.csv```获取/data/sales 下的所有 csv 文件。
* ```/data/sales/20??/**```获取20世纪的所有文件
* ```/data/sales/2004/*/12/[XY]1?.csv```获取2004年12月开始的所有 csv 文件, 以2位数字作为前缀的 X 或 Y

必须在数据集中指定容器。 因此, 你的通配符路径必须包含根文件夹中的文件夹路径。

* **分区根路径**:如果你的文件源中的```key=value```分区文件夹格式 (即 year = 2019), 则可以要求 ADF 将该分区文件夹树的顶层分配给数据流数据流中的列名称。

首先, 设置一个通配符, 以包括所有作为分区文件夹的路径, 以及要读取的叶文件。

![分区源文件设置](media/data-flow/partfile2.png "分区文件设置")

现在, 使用 "分区根路径" 设置来告诉 ADF 文件夹结构的顶层。 现在, 查看数据内容时, 会看到 ADF 会添加在每个文件夹级别中找到的已解析分区。

![分区根路径](media/data-flow/partfile1.png "分区根路径预览")

* **文件列表**:这是一个文件集。 创建一个文本文件, 其中包含要处理的相对路径文件的列表。 指向此文本文件。
* **要存储文件名的列**:将源文件的名称存储在数据中的列中。 请在此处输入新名称以存储文件名字符串。
* **完成后**:选择在数据流运行后对源文件执行任何操作、删除源文件或移动源文件。 移动的路径是相对路径。

若要将源文件移到其他位置, 请先选择 "移动" 进行文件操作。 然后, 设置 "从" 目录。 如果没有为路径使用任何通配符, 则 "源" 设置将是与源文件夹相同的文件夹。

如果源路径带有通配符, 则语法如下所示:

```/data/sales/20??/**/*.csv```

你可以指定 "from" 作为

```/data/sales```

和 "to" as

```/backup/priorSales```

在这种情况下,/data/sales 下的所有文件都将移动到/backup/priorSales。

### <a name="sql-datasets"></a>SQL 数据集

如果源在 SQL 数据库或 SQL 数据仓库中, 则可以使用其他选项进行源文件管理。

* **查询**：输入针对源的 SQL 查询。 此设置将重写您在数据集中选择的任何表。 请注意, 此处不支持**Order By**子句, 但你可以设置完整的 SELECT FROM 语句。 你还可以使用用户定义的表函数。 **select * From udfGetData ()** 是返回表的 SQL 中的 UDF。 此查询将生成可以在数据流中使用的源表。
* **批大小**：输入批大小, 将大数据分成多个读取。
* **隔离级别**:ADF 中的 SQL 源默认情况下, 未提交读取数据流。 可以将此处的隔离级别更改为以下值之一:
* 提交读
* 未提交读
* 可重复读
* 可串行
* 无 (忽略隔离级别)

![隔离级别](media/data-flow/isolationlevel.png "隔离级别")

> [!NOTE]
> 仅当您从管道运行 (管道调试或执行运行) 中的数据流开始使用管道中的 "执行数据流" 活动时, 才运行文件操作。 文件操作*不会*在数据流调试模式下运行。

### <a name="projection"></a>投影

与数据集中的架构一样, 源中的投影定义源数据中的数据列、类型和格式。 

!["投影" 选项卡上的设置](media/data-flow/source3.png "投影")

如果文本文件没有定义的架构, 请选择 "**检测数据类型**", 以便数据工厂将采样并推断数据类型。 选择 "**定义默认格式**" 以自动检测默认数据格式。 

您可以在以后的派生列转换中修改列数据类型。 使用 select 转换来修改列名称。

![默认数据格式的设置](media/data-flow/source2.png "默认格式")

### <a name="add-dynamic-content"></a>添加动态内容
单击 "设置" 面板中的字段内部时, 将显示 "添加动态内容" 的超链接。 选择启动表达式生成器时, 您将使用表达式、静态文本值或参数动态地设置值。

![参数](media/data-flow/params6.png "参数")

## <a name="next-steps"></a>后续步骤

开始生成[派生列转换](data-flow-derived-column.md)和[select 转换](data-flow-select.md)。
